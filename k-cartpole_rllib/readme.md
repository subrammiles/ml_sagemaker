Project Architecture
cartpole_rllib_sagemaker/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train_cartpole.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_sagemaker.py
â”‚   â”œâ”€â”€ download_model.py
â”‚   â”œâ”€â”€ inference_local.py
â”‚   â””â”€â”€ cleanup.py
â”‚
â””â”€â”€ config.py


âš ï¸ Notice:

No inference endpoint script

No model server

RL models are usually deployed offline (as your doc explains


ğŸ¯ Full Architecture Flow

From your diagram 

10CartPole Balancing with RLlibâ€¦

:

Notebook (Controller)
        â†“
SageMaker Training Job
        â†“
S3 Model Artifact
        â†“
Download Checkpoint
        â†“
Local Inference (Application)


This is how 90% of RL systems are deployed.